{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ae253d",
   "metadata": {},
   "source": [
    "### Por qué la regla de Hebb **pura** no aprende la compuerta AND\n",
    "\n",
    "**Idea clave:** Hebb refuerza coactivaciones pero **no corrige errores** ni **ajusta el sesgo**. Para AND, eso hace que (1,0) y (0,1) queden mal clasificadas como 1.\n",
    "\n",
    "**Definición (Hebb clásica, supervisada):**\n",
    "Datos $x\\in\\{0,1\\}^2$, etiqueta $y\\in\\{0,1\\}$. Actualización:\n",
    "\n",
    "$$\n",
    "\\Delta w=\\eta\\, x\\, y,\\qquad \\Delta b=0,\n",
    "$$\n",
    "\n",
    "con neurona $ \\hat y=\\mathbb{1}[\\,w^\\top x + b>0\\,]$.\n",
    "\n",
    "**Conjunto AND:**\n",
    "\n",
    "$$\n",
    "(0,0)\\mapsto 0,\\quad (0,1)\\mapsto 0,\\quad (1,0)\\mapsto 0,\\quad (1,1)\\mapsto 1.\n",
    "$$\n",
    "\n",
    "**Tras una pasada por los datos:**\n",
    "Solo $(1,1)$ tiene $y=1$, por tanto\n",
    "\n",
    "$$\n",
    "w=\\eta(1,1)^\\top,\\qquad b=0.\n",
    "$$\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$\n",
    "w^\\top(1,0)=\\eta>0,\\quad w^\\top(0,1)=\\eta>0,\\quad w^\\top(1,1)=2\\eta>0,\n",
    "$$\n",
    "\n",
    "lo que produce $\\hat y=1$ para $(1,0)$ y $(0,1)$, que es **incorrecto**.\n",
    "\n",
    "**Qué faltó:** Para que AND funcione se requiere un **sesgo negativo** que suba el umbral efectivo:\n",
    "\n",
    "$$\n",
    "\\text{aceptar solo }(1,1)\\ \\Longleftrightarrow\\ b\\in(-2\\eta,\\,-\\eta).\n",
    "$$\n",
    "\n",
    "La regla Hebb pura **no** ajusta $b$ ni reduce pesos ante falsos positivos, así que no puede “aprender” AND por sí sola.\n",
    "\n",
    "**Conclusión:** Hebb pura falla en AND. Funciona si:\n",
    "\n",
    "1. se **impone** un sesgo $b$ adecuado o una entrada constante $x_0\\equiv 1$ con peso inhibitorio aprendido, o\n",
    "2. se usa una regla con **corrección de error** (perceptrón, delta rule) que ajuste $w,b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ed0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos Hebb: [1. 1.] bias: 0.0\n",
      "Predicción sin sesgo: [0 1 1 1]\n",
      "Predicción con sesgo negativo: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos AND\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "eta = 1.0\n",
    "\n",
    "# Hebb pura (sin sesgo)\n",
    "w = np.zeros(2)\n",
    "for xi, yi in zip(X, y):\n",
    "    w += eta * xi * yi  # solo (1,1) suma\n",
    "b = 0.0\n",
    "\n",
    "def predict(X, w, b):\n",
    "    return (X @ w + b > 0).astype(int)\n",
    "\n",
    "print(\"Pesos Hebb:\", w, \"bias:\", b)\n",
    "print(\"Predicción sin sesgo:\", predict(X, w, b))  # Falla en (1,0) y (0,1)\n",
    "\n",
    "# Fijar un sesgo negativo adecuado\n",
    "b_ok = -1.5 * eta  # en (-2*eta, -eta)\n",
    "print(\"Predicción con sesgo negativo:\", predict(X, w, b_ok))  # Ahora es AND correcto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847d572",
   "metadata": {},
   "source": [
    "Sí puedes interpretarla y, de hecho, tu tabla muestra **que con sesgo** la Hebb supervisada **sí** puede implementar AND. El “no puede” clásico se refiere a Hebb **sin sesgo**.\n",
    "\n",
    "### Cómo leer tu tabla\n",
    "\n",
    "* Tres primeras columnas (izq., resaltadas): $x_1,\\ x_2,\\ t\\in\\{+1,-1\\}$ con codificación bipolar. Para AND: $t=+1$ solo cuando $(x_1,x_2)=(+1,+1)$; en los demás casos $t=-1$.\n",
    "* Tres columnas derechas: acumulados de la regla Hebb supervisada\n",
    "\n",
    "  $$\n",
    "  \\Delta w = t\\,x,\\quad \\Delta b = t,\n",
    "  $$\n",
    "\n",
    "  por lo que después de cada fila:\n",
    "\n",
    "  $$\n",
    "  w_1 \\leftarrow w_1 + t\\,x_1,\\qquad\n",
    "  w_2 \\leftarrow w_2 + t\\,x_2,\\qquad\n",
    "  b \\leftarrow b + t.\n",
    "  $$\n",
    "* Clasificador resultante: $\\hat y=\\mathrm{sign}(w_1 x_1 + w_2 x_2 + b)$.\n",
    "\n",
    "### Qué está pasando en tus números\n",
    "\n",
    "* Observas $w_1\\approx w_2$ creciendo y $b$ volviéndose **más negativo** (suma de muchas etiquetas $-1$).\n",
    "* En algún punto, por ejemplo con $(w_1,w_2,b)=(4,4,-4)$, las puntuaciones son:\n",
    "\n",
    "  $$\n",
    "  s(+1,+1)=2\\cdot4-4=4>0,\\quad\n",
    "  s(+1,-1)=0-4=-4<0,\\quad\n",
    "  s(-1,+1)=0-4=-4<0,\\quad\n",
    "  s(-1,-1)=-8-4<0,\n",
    "  $$\n",
    "\n",
    "  que coincide exactamente con AND en bipolar: solo $(+1,+1)$ es positivo.\n",
    "\n",
    "### Conclusión operativa\n",
    "\n",
    "* **Con sesgo aprendido** vía una entrada constante $x_0\\equiv 1$ y $\\Delta w_0=\\Delta b=t$, Hebb **sí** separa AND.\n",
    "* **Sin sesgo** ($\\Delta b=0$) Hebb fija $b=0$ y queda $w\\propto(1,1)$; entonces $w^\\top(1,0)>0$ y $w^\\top(0,1)>0$, lo que **siempre** falla para AND.\n",
    "  Ese es el caso al que se alude cuando se dice que “Hebb no puede AND”.\n",
    "\n",
    "  Sí. Se “separan” en el **espacio proyectado** por $w$, no en el plano original.\n",
    "\n",
    "* Modelo: $\\hat t=\\operatorname{sign}(s(x))$, con $s(x)=w^\\top x+b$.\n",
    "* Hebb (bipolar): $\\Delta w=t\\,x,\\ \\Delta b=t$. Cada ejemplo mueve $w$ **hacia la correlación** entrada–etiqueta.\n",
    "\n",
    "Lectura de signos y magnitudes:\n",
    "\n",
    "* $w_i$ **positivo grande** ⇒ la entrada $x_i=+1$ **empuja** $s(x)$ a $+$ (favorece $t=+1$); $x_i=-1$ la **penaliza**.\n",
    "* $w_i$ **negativo grande** ⇒ $x_i=+1$ penaliza y $x_i=-1$ favorece.\n",
    "* $b$ **negativo** desplaza el umbral para volver más **exigente** la activación.\n",
    "\n",
    "Qué implica “más positivo/negativo”:\n",
    "\n",
    "* Aumenta $|s(x)|$ y por tanto el **margen** $\\gamma=\\min_k \\frac{t_k\\,s(x_k)}{\\|w\\|}$. Si tus updates alinean $w$ con el patrón positivo, $\\gamma$ crece y la clasificación se vuelve **robusta**.\n",
    "* En tu tabla, muchos $t=-1$ ⇒ $b$ se hace muy negativo. Eso fuerza a que solo $(+1,+1)$ logre $s(x)>0$:\n",
    "\n",
    "  $$\n",
    "  s(+1,+1)=w_1+w_2+b,\\quad\n",
    "  s(+1,-1)=w_1-w_2+b,\\quad\n",
    "  s(-1,+1)=-w_1+w_2+b,\\quad\n",
    "  s(-1,-1)=-w_1-w_2+b.\n",
    "  $$\n",
    "\n",
    "  Con $w_1\\approx w_2>0$ y $b\\ll0$, solo el primero queda $>\\!0$ ⇒ AND.\n",
    "\n",
    "Notas:\n",
    "\n",
    "* Sí, crecer en magnitud **separa** las clases tras la proyección $x\\mapsto s(x)$.\n",
    "* Hebb puede hacer que $\\|w\\|$ “explote”; la **dirección** de $w$ y el **signo** de $s(x)$ son lo relevante. Normalizar $w$ o parar por margen evita explosión.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
